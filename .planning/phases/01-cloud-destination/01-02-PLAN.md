---
phase: 01-cloud-destination
plan: 02
type: execute
---

<objective>
Integrate cloud folder destination into backup flow, routing backups to cloud-synced folder.

Purpose: Make backups automatically sync to cloud by writing to Dropbox/GDrive folder.
Output: Modified backup engine that writes to cloud folder destination.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-cloud-destination/01-01-SUMMARY.md

**Prior work:**
- 01-01 created `lib/cloud-folder-detector.sh` with detection functions
- 01-01 added config options to `templates/backup-config.sh`

**Key files:**
@lib/backup-lib.sh (core backup functions)
@bin/backup-now.sh (main backup command)
@lib/cloud-folder-detector.sh (from 01-01)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add cloud folder destination resolution</name>
  <files>lib/backup-lib.sh</files>
  <action>
Add a new function `resolve_backup_destinations()` to `lib/backup-lib.sh` that:

1. Sources `lib/cloud-folder-detector.sh` if not already loaded
2. Checks if `CLOUD_FOLDER_ENABLED=true`
3. If enabled:
   - If `CLOUD_FOLDER_PATH` is set, validate it exists and is writable
   - If empty, call `detect_all_cloud_folders()` and use first available
   - Set `CLOUD_BACKUP_DIR` to `$CLOUD_FOLDER_PATH/$CLOUD_PROJECT_FOLDER`
   - Create the directory structure: `$CLOUD_BACKUP_DIR/{files,archived,databases}`
4. Set destination variables:
   - If cloud enabled: `PRIMARY_BACKUP_DIR=$CLOUD_BACKUP_DIR`
   - If `CLOUD_FOLDER_ALSO_LOCAL=true`: `SECONDARY_BACKUP_DIR=$BACKUP_DIR` (local)
   - If cloud disabled: `PRIMARY_BACKUP_DIR=$BACKUP_DIR`, no secondary
5. Export: `PRIMARY_FILES_DIR`, `PRIMARY_ARCHIVED_DIR`, `PRIMARY_DATABASE_DIR` (and secondary if applicable)

Add this function near the top of backup-lib.sh after variable initialization.

Also add a helper `ensure_backup_dirs()` that creates both primary and secondary directory structures.
  </action>
  <verify>
    source lib/backup-lib.sh && type resolve_backup_destinations
  </verify>
  <done>
    - `resolve_backup_destinations()` function exists
    - Sets PRIMARY_BACKUP_DIR and optionally SECONDARY_BACKUP_DIR
    - Creates directory structures in both destinations
    - Falls back gracefully if cloud folder unavailable
  </done>
</task>

<task type="auto">
  <name>Task 2: Update backup-now.sh to use cloud destination</name>
  <files>bin/backup-now.sh</files>
  <action>
Modify `bin/backup-now.sh` to use the new destination routing:

1. After sourcing libraries and loading config, call `resolve_backup_destinations()`

2. Modify file backup logic to:
   - Copy to `PRIMARY_FILES_DIR` (cloud folder when enabled)
   - Archive old versions to `PRIMARY_ARCHIVED_DIR`
   - If `SECONDARY_BACKUP_DIR` is set (CLOUD_FOLDER_ALSO_LOCAL=true), also copy to secondary

3. Modify database backup calls to use `PRIMARY_DATABASE_DIR` (and secondary if set)

4. Update log messages to indicate destination:
   - "Backing up to: $PRIMARY_BACKUP_DIR" (shows cloud folder path)
   - "Also backing up locally: $SECONDARY_BACKUP_DIR" (if applicable)

5. Add fallback: If primary (cloud) write fails, try secondary (local) and log warning

Keep changes minimal - only modify destination paths, don't restructure the entire file.
The key change is replacing `$FILES_DIR` with `$PRIMARY_FILES_DIR`, etc.
  </action>
  <verify>
    # Test with cloud folder disabled (should work as before)
    CLOUD_FOLDER_ENABLED=false ./bin/backup-now.sh --help

    # Check that the script sources cloud-folder-detector
    grep -q "cloud-folder-detector" bin/backup-now.sh || grep -q "resolve_backup_destinations" bin/backup-now.sh
  </verify>
  <done>
    - backup-now.sh calls resolve_backup_destinations()
    - Uses PRIMARY_* variables for destinations
    - Supports dual-write when CLOUD_FOLDER_ALSO_LOCAL=true
    - Falls back to local if cloud folder unavailable
    - Backwards compatible when CLOUD_FOLDER_ENABLED=false
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `resolve_backup_destinations()` exists in backup-lib.sh
- [ ] backup-now.sh uses resolved destinations
- [ ] With CLOUD_FOLDER_ENABLED=false, behavior unchanged
- [ ] With CLOUD_FOLDER_ENABLED=true, writes to cloud folder
- [ ] Directory structure created in destination
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- Backup writes to cloud folder when enabled
- Backwards compatible with existing configs
- Phase 1 complete
</success_criteria>

<output>
After completion, create `.planning/phases/01-cloud-destination/01-02-SUMMARY.md`
</output>
