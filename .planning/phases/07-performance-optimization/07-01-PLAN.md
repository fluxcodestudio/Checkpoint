---
phase: 07-performance-optimization
plan: 01
type: execute
---

<objective>
Optimize change detection by parallelizing git commands and adding early exit.

Purpose: Reduce backup trigger latency from 500ms-2s to <200ms for incremental backups.
Output: Faster change detection in backup-daemon.sh and backup-now.sh.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/codebase/ARCHITECTURE.md
@.planning/codebase/CONCERNS.md

@bin/backup-daemon.sh
@bin/backup-now.sh

**Established patterns:**
- PID-file-based locking
- set -e compatibility (use `$((var + 1))` not `((var++))`)
- trap-based cleanup

**Current bottleneck (from backup-daemon.sh:248-263):**
```bash
# Sequential git commands - each spawns subprocess
git diff --name-only >> "$changed_files" 2>/dev/null || true
git diff --cached --name-only >> "$changed_files" 2>/dev/null || true
git ls-files --others --exclude-standard >> "$changed_files" 2>/dev/null || true
```

**Constraint:** Must maintain backward compatibility with non-git directories (find fallback).
</context>

<tasks>

<task type="auto">
  <name>Task 1: Parallelize git change detection commands</name>
  <files>bin/backup-daemon.sh, lib/backup-lib.sh</files>
  <action>
Create a new function `get_changed_files_fast()` in backup-lib.sh that:
1. Runs all 3 git commands in parallel using background jobs (`&`)
2. Waits for all to complete (`wait`)
3. Combines results into single temp file
4. Returns early if first command finds changes AND we only need "any changes" (not full list)

Pattern:
```bash
get_changed_files_fast() {
    local output_file="$1"
    local need_full_list="${2:-false}"
    local tmp1 tmp2 tmp3
    tmp1=$(mktemp) tmp2=$(mktemp) tmp3=$(mktemp)

    # Parallel execution
    git diff --name-only > "$tmp1" 2>/dev/null &
    local pid1=$!
    git diff --cached --name-only > "$tmp2" 2>/dev/null &
    local pid2=$!
    git ls-files --others --exclude-standard > "$tmp3" 2>/dev/null &
    local pid3=$!

    # Wait for all
    wait $pid1 $pid2 $pid3 2>/dev/null || true

    # Combine and dedupe
    cat "$tmp1" "$tmp2" "$tmp3" | sort -u > "$output_file"
    rm -f "$tmp1" "$tmp2" "$tmp3"
}
```

Update backup-daemon.sh to use `get_changed_files_fast()` instead of sequential commands.

Avoid: Don't break the non-git fallback path (find-based detection must still work).
  </action>
  <verify>
1. `time bin/backup-daemon.sh --dry-run` shows faster change detection
2. Works in git repo (parallel git)
3. Works in non-git directory (find fallback)
  </verify>
  <done>
- `get_changed_files_fast()` function exists in backup-lib.sh
- backup-daemon.sh uses parallel detection
- Non-git fallback still works
  </done>
</task>

<task type="auto">
  <name>Task 2: Add early-exit for "has changes" check</name>
  <files>bin/backup-daemon.sh, lib/backup-lib.sh</files>
  <action>
Add a fast `has_changes()` function that returns true/false without building full file list:
1. Check git status porcelain (single command, fast)
2. If any output, return 0 (has changes)
3. If no output, return 1 (no changes)

```bash
has_changes() {
    # Fast check - don't need full list, just yes/no
    if git rev-parse --git-dir > /dev/null 2>&1; then
        # Git repo: single status check
        [ -n "$(git status --porcelain 2>/dev/null | head -1)" ]
    else
        # Non-git: check for recent modifications
        [ -n "$(find . -type f -mmin -${1:-60} ! -path '*/.git/*' ! -path '*/node_modules/*' ! -path '*/backups/*' 2>/dev/null | head -1)" ]
    fi
}
```

Update backup-daemon.sh main loop to:
1. First call `has_changes` (fast)
2. Only if true, call `get_changed_files_fast` (builds full list)
3. Skip backup cycle entirely if no changes

Avoid: Don't remove the full file list collection - it's still needed for selective backup.
  </action>
  <verify>
1. `has_changes` returns 0 after file edit, 1 when clean
2. Backup daemon skips cycle when no changes (check logs)
3. Full file list still generated when backup runs
  </verify>
  <done>
- `has_changes()` function exists
- Daemon loop uses fast check before full detection
- Clean projects skip backup cycle (log shows "no changes")
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `time bin/backup-daemon.sh --dry-run` completes in <200ms for "no changes" case
- [ ] Change detection still works correctly (create file, verify detected)
- [ ] Non-git directories still work (test in /tmp)
- [ ] No bash errors with `set -e` enabled
</verification>

<success_criteria>
- All tasks completed
- Parallel git commands working
- Early-exit for no-changes case
- Backward compatibility maintained
- No regressions in existing functionality
</success_criteria>

<output>
After completion, create `.planning/phases/07-performance-optimization/07-01-SUMMARY.md`
</output>
