# Milestone v1.0: Automated Backup System

**Status:** SHIPPED 2026-01-11
**Phases:** 1-6
**Total Plans:** 13

## Overview

Transform the existing backup infrastructure into a fully automatic, invisible system. Starting with cloud folder destination (leveraging Dropbox/GDrive desktop sync), add activity-based triggers with debouncing, integrate with Claude Code events, implement fallback chains for reliability, add tiered retention for efficient storage, and finish with dashboard/monitoring for visibility.

## Phases

### Phase 1: Cloud Destination Setup

**Goal**: Configure master backup folder in user's cloud-synced directory (Dropbox/GDrive) so backups auto-sync to cloud without API calls
**Depends on**: Nothing (first phase)
**Plans**: 2 plans

Plans:
- [x] 01-01: Cloud folder detection and configuration
- [x] 01-02: Backup destination routing to cloud folder

**Details:**
Created `lib/cloud-folder-detector.sh` with detection functions for Dropbox, Google Drive, iCloud, and OneDrive. Added config options to `templates/backup-config.sh`. Modified backup engine to write to cloud folder destination.

### Phase 2: Activity Triggers

**Goal**: Watch for file changes and trigger backups after 60s of inactivity (debouncing)
**Depends on**: Phase 1
**Plans**: 2 plans

Plans:
- [x] 02-01: File watcher implementation with debouncing
- [x] 02-02: Integration with backup engine

**Details:**
Created `lib/file-watcher.sh` with fswatch-based watching and debounce logic. Added watcher management commands. Created LaunchAgent template for watcher persistence. Integrated with install/uninstall lifecycle.

### Phase 3: Claude Code Integration

**Goal**: Trigger backups on Claude Code events (conversation end, file changes, commits)
**Depends on**: Phase 2
**Plans**: 2 plans

Plans:
- [x] 03-01: Create hook scripts and settings template
- [x] 03-02: Event-triggered backup orchestration

**Details:**
Created hook scripts for backup triggers. Created `templates/claude-settings.json` with hooks configuration. Added hooks installation to install.sh and cleanup to uninstall.sh.

### Phase 4: Fallback Chain

**Goal**: Implement reliability chain: cloud folder → rclone API → local queue
**Depends on**: Phase 1
**Plans**: 2 plans

Plans:
- [x] 04-01: Fallback detection and switching logic
- [x] 04-02: Local queue for offline scenarios

**Details:**
Added cloud folder health check function. Integrated rclone API as middle fallback tier. Created queue infrastructure with enqueue/dequeue/process functions. Added queue processor with retry on connectivity.

### Phase 5: Tiered Retention

**Goal**: Manage snapshot lifecycle with hourly/daily/weekly/monthly tiers (like Time Machine)
**Depends on**: Phase 1
**Plans**: 2 plans

Plans:
- [x] 05-01: Retention policy engine
- [x] 05-02: Cleanup and pruning automation

**Details:**
Created `lib/retention-policy.sh` with tier classification. Added pruning candidate identification functions. Integrated tiered retention into backup-cleanup.sh. Added automatic tiered cleanup to daemon.

### Phase 6: Dashboard & Monitoring

**Goal**: Status bar indicator, all-projects dashboard, sub-minute restore capability
**Depends on**: Phases 1-5
**Plans**: 3 plans

Plans:
- [x] 06-01: Status bar indicator implementation
- [x] 06-02: All-projects dashboard view
- [x] 06-03: Restore interface and capability

**Details:**
Created global status aggregation library. Created backup status indicator CLI. Updated tmux integration for global status. Created all-projects dashboard command with detailed project view. Added point-in-time restore library with timeline view to restore wizard.

---

## Milestone Summary

**Key Decisions:**
- Cloud folder as primary destination (Rationale: User's Dropbox/GDrive folder auto-syncs via desktop app)
- Debounce-based triggers (60s) (Rationale: Captures natural pause points without excessive snapshots)
- Tiered retention (Rationale: Granular recent history, compressed older history)
- Fallback chain priority (Rationale: Cloud folder → rclone API → local queue maximizes reliability)
- macOS only for v1 (Rationale: Reduces complexity, user's primary platform)
- Health thresholds: >24h warning, >72h error (Rationale: Balance alerting and noise)
- Use $((var + 1)) not ((var++)) (Rationale: set -e compatibility)

**Issues Resolved:**
- set -e compatibility issues in retention-policy.sh when sourced by dashboard
- Derive FILES_DIR from BACKUP_DIR for config order independence

**Issues Deferred:**
- None

**Technical Debt Incurred:**
- None

---

_For current project status, see .planning/ROADMAP.md_
